{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_LYOEqwH-WX"
   },
   "source": [
    "#A Basic implementation of Sentiment Analysis with Sequence Models(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIXQhuTalRc2"
   },
   "source": [
    "*As an introduction project to RNN, I am using LSTMs to build a module for Sentiment Analysis in Keras*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sqoNUt0MeuB7"
   },
   "source": [
    "*Import the Tensorflow framework*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6F4SmKqhtdc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azJQDVpLeVh-"
   },
   "source": [
    "*Load the IMDB dataset with a cap on the top most frequent words to consider as **5000**. All the reviews are preprocessed and encodedas a **sequence of word indices**. The indices pertains to the **overall frequency** of the word in the data set.For example integer **n** encodes for the **nth most frequent word** in the data.All the reviews are labelled as **negative-0** and **positive-1**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "HrpZR6vsl7TS",
    "outputId": "c5c231e7-e64a-4914-d7c8-1185f11eae33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "Load dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "vocabulary_size = 5000# top most frequent words to consider\n",
    "\n",
    "(X_train, y_train),(X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "\n",
    "print('Load dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2Sv5VcEhX3r"
   },
   "source": [
    "*View a sample label with its index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "B0dmH0y6mHC9",
    "outputId": "1f4f6891-6539-42b7-fa53-d033d461e78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---label---\n",
      "1\n",
      "---review---\n",
      "[1, 785, 189, 438, 47, 110, 142, 7, 6, 2, 120, 4, 236, 378, 7, 153, 19, 87, 108, 141, 17, 1004, 5, 2, 883, 2, 23, 8, 4, 136, 2, 2, 4, 2, 43, 1076, 21, 1407, 419, 5, 2, 120, 91, 682, 189, 2818, 5, 9, 1348, 31, 7, 4, 118, 785, 189, 108, 126, 93, 2, 16, 540, 324, 23, 6, 364, 352, 21, 14, 9, 93, 56, 18, 11, 230, 53, 771, 74, 31, 34, 4, 2834, 7, 4, 22, 5, 14, 11, 471, 9, 2, 34, 4, 321, 487, 5, 116, 15, 2, 4, 22, 9, 6, 2286, 4, 114, 2679, 23, 107, 293, 1008, 1172, 5, 328, 1236, 4, 1375, 109, 9, 6, 132, 773, 2, 1412, 8, 1172, 18, 2, 29, 9, 276, 11, 6, 2768, 19, 289, 409, 4, 2, 2140, 2, 648, 1430, 2, 2, 5, 27, 3000, 1432, 2, 103, 6, 346, 137, 11, 4, 2768, 295, 36, 2, 725, 6, 3208, 273, 11, 4, 1513, 15, 1367, 35, 154, 2, 103, 2, 173, 7, 12, 36, 515, 3547, 94, 2547, 1722, 5, 3547, 36, 203, 30, 502, 8, 361, 12, 8, 989, 143, 4, 1172, 3404, 10, 10, 328, 1236, 9, 6, 55, 221, 2989, 5, 146, 165, 179, 770, 15, 50, 713, 53, 108, 448, 23, 12, 17, 225, 38, 76, 4397, 18, 183, 8, 81, 19, 12, 45, 1257, 8, 135, 15, 2, 166, 4, 118, 7, 45, 2, 17, 466, 45, 2, 4, 22, 115, 165, 764, 2, 5, 1030, 8, 2973, 73, 469, 167, 2127, 2, 1568, 6, 87, 841, 18, 4, 22, 4, 192, 15, 91, 7, 12, 304, 273, 1004, 4, 1375, 1172, 2768, 2, 15, 4, 22, 764, 55, 2, 5, 14, 4233, 2, 4, 1375, 326, 7, 4, 4760, 1786, 8, 361, 1236, 8, 989, 46, 7, 4, 2768, 45, 55, 776, 8, 79, 496, 98, 45, 400, 301, 15, 4, 1859, 9, 4, 155, 15, 66, 2, 84, 5, 14, 22, 1534, 15, 17, 4, 167, 2, 15, 75, 70, 115, 66, 30, 252, 7, 618, 51, 9, 2161, 4, 3130, 5, 14, 1525, 8, 2, 15, 2, 165, 127, 1921, 8, 30, 179, 2532, 4, 22, 9, 906, 18, 6, 176, 7, 1007, 1005, 4, 1375, 114, 4, 105, 26, 32, 55, 221, 11, 68, 205, 96, 5, 4, 192, 15, 4, 274, 410, 220, 304, 23, 94, 205, 109, 9, 55, 73, 224, 259, 3786, 15, 4, 22, 528, 1645, 34, 4, 130, 528, 30, 685, 345, 17, 4, 277, 199, 166, 281, 5, 1030, 8, 30, 179, 4442, 444, 2, 9, 6, 371, 87, 189, 22, 5, 31, 7, 4, 118, 7, 4, 2068, 545, 1178, 829]\n"
     ]
    }
   ],
   "source": [
    "print('---label---')\n",
    "print(y_train[10])\n",
    "print('---review---')\n",
    "print(X_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teq5ZnGGiN7K"
   },
   "source": [
    "*Mapping the review back to its original words.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "CE5gnokZwImn",
    "outputId": "5024ea44-1f78-41ed-cff1-18c94b5d5a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "---review with words---\n",
      "['the', 'clear', 'fact', 'entertaining', 'there', 'life', 'back', 'br', 'is', 'and', 'show', 'of', 'performance', 'stars', 'br', 'actors', 'film', 'him', 'many', 'should', 'movie', 'reasons', 'to', 'and', 'reading', 'and', 'are', 'in', 'of', 'scenes', 'and', 'and', 'of', 'and', 'out', 'compared', 'not', 'boss', 'yes', 'to', 'and', 'show', 'its', 'disappointed', 'fact', 'raw', 'to', 'it', 'justice', 'by', 'br', 'of', 'where', 'clear', 'fact', 'many', 'your', 'way', 'and', 'with', 'city', 'nice', 'are', 'is', 'along', 'wrong', 'not', 'as', 'it', 'way', 'she', 'but', 'this', 'anything', 'up', \"haven't\", 'been', 'by', 'who', 'of', 'choices', 'br', 'of', 'you', 'to', 'as', 'this', \"i'd\", 'it', 'and', 'who', 'of', 'shot', \"you'll\", 'to', 'love', 'for', 'and', 'of', 'you', 'it', 'is', 'sequels', 'of', 'little', 'quest', 'are', 'seen', 'watched', 'front', 'chemistry', 'to', 'simply', 'alive', 'of', 'chris', 'being', 'it', 'is', 'say', 'easy', 'and', 'cry', 'in', 'chemistry', 'but', 'and', 'all', 'it', 'maybe', 'this', 'is', 'wing', 'film', 'job', 'live', 'of', 'and', 'relief', 'and', 'level', 'names', 'and', 'and', 'to', 'be', 'stops', 'serial', 'and', 'watch', 'is', 'men', 'go', 'this', 'of', 'wing', 'american', 'from', 'and', 'moving', 'is', 'accepted', 'put', 'this', 'of', 'jerry', 'for', 'places', 'so', 'work', 'and', 'watch', 'and', 'lot', 'br', 'that', 'from', 'sometimes', 'wondered', 'make', 'department', 'introduced', 'to', 'wondered', 'from', 'action', 'at', 'turns', 'in', 'low', 'that', 'in', 'gay', \"i'm\", 'of', 'chemistry', 'bible', 'i', 'i', 'simply', 'alive', 'it', 'is', 'time', 'done', 'inspector', 'to', 'watching', 'look', 'world', 'named', 'for', 'more', 'tells', 'up', 'many', 'fans', 'are', 'that', 'movie', 'music', 'her', 'get', 'grasp', 'but', 'seems', 'in', 'people', 'film', 'that', 'if', 'explain', 'in', 'why', 'for', 'and', 'find', 'of', 'where', 'br', 'if', 'and', 'movie', 'throughout', 'if', 'and', 'of', 'you', 'best', 'look', 'red', 'and', 'to', 'recently', 'in', 'successfully', 'much', 'unfortunately', 'going', 'dan', 'and', 'stuck', 'is', 'him', 'sequences', 'but', 'of', 'you', 'of', 'enough', 'for', 'its', 'br', 'that', 'beautiful', 'put', 'reasons', 'of', 'chris', 'chemistry', 'wing', 'and', 'for', 'of', 'you', 'red', 'time', 'and', 'to', 'as', 'companion', 'and', 'of', 'chris', 'less', 'br', 'of', 'subplots', 'torture', 'in', 'low', 'alive', 'in', 'gay', 'some', 'br', 'of', 'wing', 'if', 'time', 'actual', 'in', 'also', 'side', 'any', 'if', 'name', 'takes', 'for', 'of', 'friendship', 'it', 'of', '10', 'for', 'had', 'and', 'great', 'to', 'as', 'you', 'students', 'for', 'movie', 'of', 'going', 'and', 'for', 'bad', 'well', 'best', 'had', 'at', 'woman', 'br', 'musical', 'when', 'it', 'caused', 'of', 'gripping', 'to', 'as', 'gem', 'in', 'and', 'for', 'and', 'look', 'end', 'gene', 'in', 'at', 'world', 'aliens', 'of', 'you', 'it', 'meet', 'but', 'is', 'quite', 'br', 'western', 'ideas', 'of', 'chris', 'little', 'of', 'films', 'he', 'an', 'time', 'done', 'this', 'were', 'right', 'too', 'to', 'of', 'enough', 'for', 'of', 'ending', 'become', 'family', 'beautiful', 'are', 'make', 'right', 'being', 'it', 'time', 'much', 'bit', 'especially', 'craig', 'for', 'of', 'you', 'parts', 'bond', 'who', 'of', 'here', 'parts', 'at', 'due', 'given', 'movie', 'of', 'once', 'give', 'find', 'actor', 'to', 'recently', 'in', 'at', 'world', 'dolls', 'loved', 'and', 'it', 'is', 'video', 'him', 'fact', 'you', 'to', 'by', 'br', 'of', 'where', 'br', 'of', 'grown', 'fight', 'culture', 'leads']\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "index2word = {i:word for word, i in word_index.items()}\n",
    "print('---review with words---')\n",
    "print([index2word.get(i, ' ') for i in X_train[10]])\n",
    "print('---label---')\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBGTN8GslXuO"
   },
   "source": [
    "*Looking at the host of positive words present in the review it is clearly labelled as positive-1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_7KU1JDlqHD"
   },
   "source": [
    "**Padding Sequences:** *Next we need to apply **padding** to the reviews so that the reviews fed to our RNN are all of same length.We truncate longer reviews and apply padding to shorter reviews with null values.Maximum number of words retained in the reviews is **500**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "mXA0hQtUwJu_",
    "outputId": "18457ac0-4764-44cc-e1d0-aad968f84736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2697\n",
      "Minimum review length: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print('Maximum review length: {}'.format(len(max((X_train+X_test), key = len))))\n",
    "print('Minimum review length: {}'.format(len(min((X_train+X_test), key = len))))\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen = max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g331_v3Csrxh"
   },
   "source": [
    "*RNN Model for Sentiment Analysis*\n",
    "* Input: word indices<\n",
    "*Output: label(**0 or 1**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "colab_type": "code",
    "id": "bCwEErPnrKWv",
    "outputId": "ac27d223-bf81-48fd-8b30-f30a56db9bd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 05:00:48.059889 140688279783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 05:00:48.101247 140688279783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 05:00:48.107120 140688279783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 05:00:48.378425 140688279783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 05:00:48.400138 140688279783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0819 05:00:48.407273 140688279783296 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "embedding_size = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocabulary_size, output_dim = embedding_size, input_length = max_words))\n",
    "model.add(LSTM(units = 100))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZadOX8P_now"
   },
   "source": [
    "*Start Model Trainig*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_TJtxjoc-7d_",
    "outputId": "14105781-a3e4-4b35-ad83-a71ce19b3121"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 05:00:49.359829 140688279783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/5\n",
      "24936/24936 [==============================] - 312s 12ms/step - loss: 0.4296 - acc: 0.7959 - val_loss: 0.3215 - val_acc: 0.8594\n",
      "Epoch 2/5\n",
      "24936/24936 [==============================] - 295s 12ms/step - loss: 0.2814 - acc: 0.8884 - val_loss: 0.3581 - val_acc: 0.8438\n",
      "Epoch 3/5\n",
      "24936/24936 [==============================] - 295s 12ms/step - loss: 0.2568 - acc: 0.8989 - val_loss: 0.2831 - val_acc: 0.9062\n",
      "Epoch 4/5\n",
      "24936/24936 [==============================] - 296s 12ms/step - loss: 0.2333 - acc: 0.9095 - val_loss: 0.2965 - val_acc: 0.8906\n",
      "Epoch 5/5\n",
      "24936/24936 [==============================] - 293s 12ms/step - loss: 0.2281 - acc: 0.9140 - val_loss: 0.2661 - val_acc: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff437328ef0>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "\n",
    "model.fit(X_train2, y_train2, validation_data = (X_valid, y_valid), batch_size = batch_size, epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Da7R1wEHgM6"
   },
   "source": [
    "*Check Model Acuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "6tIzVe12AlUd",
    "outputId": "55940211-8aa0-4fe0-ef3f-f3ccf771fea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.87148\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzqVwjdIKymv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment_analysis_with_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
